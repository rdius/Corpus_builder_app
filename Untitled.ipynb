{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core pkgs\n",
    "import streamlit as st\n",
    "import altair as alt\n",
    "## EDA Pkgs\n",
    "import base64\n",
    "import json\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "# from container_ import main_proto\n",
    "\n",
    "##############\n",
    "\n",
    "# \n",
    "def select_useful_cols(corpus):\n",
    "    \"\"\"\n",
    "    we just keep esssential cols that will be used for filtering and vizualising\n",
    "    \"\"\"\n",
    "    columns = ['name','text','title',\t'SNE',\t'TNE',\t'pertinence', 'thematic']\n",
    "    new_corpus = pd.DataFrame(corpus, columns=columns)\n",
    "    corpus_data  = pd.concat([new_corpus.drop(['SNE', 'TNE'], axis=1), new_corpus['SNE'].apply(pd.Series), new_corpus['TNE'].apply(pd.Series)], axis=1)\n",
    "    return corpus_data\n",
    "\n",
    "# \n",
    "def read_corpus(file):\n",
    "    \"\"\"\n",
    "    fxn to pars the database : corpus of thematic documents\n",
    "    \"\"\"\n",
    "    long_list = []\n",
    "    with jsonlines.open(file) as f:\n",
    "        for line in f.iter():\n",
    "            long_list.append(line)\n",
    "    my_corpus = pd.DataFrame(long_list,copy =True)\n",
    "    corpus = select_useful_cols(my_corpus)\n",
    "    return corpus\n",
    "\n",
    "\n",
    "\n",
    "def look_for_thematic_data(file,thematic):\n",
    "    '''\n",
    "    Fxn to retrive data for a given thematic data from 3M Database. Three thematics are included :\n",
    "    agriculture, hydrologie, and urbanisation\n",
    "    file : input file, the database in jsonl, in this case\n",
    "    '''\n",
    "    my_corpus = read_corpus(file) \n",
    "    \n",
    "    if thematic == 'agriculture':\n",
    "        them_mask = my_corpus['thematic']==thematic\n",
    "        query_data = my_corpus[them_mask]\n",
    "    if thematic == 'hydrologie':\n",
    "        them_mask = my_corpus['thematic']==thematic\n",
    "        query_data = my_corpus[them_mask]\n",
    "    if thematic == 'urbanisation':\n",
    "        them_mask = my_corpus['thematic']==thematic\n",
    "        query_data = my_corpus[them_mask]\n",
    "    return query_data\n",
    "\n",
    "def get_table_download_link_csv(df):\n",
    "    \"\"\"\n",
    "    fnx to dowload the query results in csv file format\n",
    "    \"\"\"\n",
    "    #csv = df.to_csv(index=False)\n",
    "    csv = df.to_csv(index=False, sep=\"\\t\").encode()\n",
    "    #b64 = base64.b64encode(csv.encode()).decode() \n",
    "    b64 = base64.b64encode(csv).decode()\n",
    "    href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"data.csv\" target=\"_blank\">Download csv file</a>'\n",
    "    return href    \n",
    "\n",
    "def process_date(corpus_data):\n",
    "    \"\"\"\n",
    "    this fxn is used to categorize data during vizualisation.\n",
    "    related to tne_color() fxn below\n",
    "    \"\"\"\n",
    "\n",
    "    corpus_data['date'] = pd.to_datetime(corpus_data['date']) \n",
    "    corpus_data_tne = corpus_data[corpus_data['date'].notnull()]\n",
    "    # corpus_data_tne.head(2)\n",
    "    range_1 = corpus_data_tne[corpus_data_tne['date']>='2019-01-01']\n",
    "    # range_1\n",
    "    mask = (corpus_data_tne['date'] > '2015-01-01') & (corpus_data_tne['date'] <= '2019-01-01')\n",
    "    range_2 = corpus_data_tne[mask]\n",
    "    # range_2\n",
    "    range_3 = corpus_data_tne[corpus_data_tne['date']<='2015-01-01']\n",
    "    return corpus_data_tne, range_1, range_2, range_3    \n",
    "\n",
    "def temporal_filter(corpus_data):\n",
    "    \"\"\"\n",
    "    TO DO : take into account temporal filter (range for data query) as its doesn't works yet in UI.\n",
    "    \"\"\"\n",
    "    \n",
    "    return filtered_data\n",
    "    \n",
    "def sne_color(df):\n",
    "    \"\"\"\n",
    "    fnx to differentiate pie diagram colors, for spatial named entities\n",
    "    \"\"\"\n",
    "    colors = []\n",
    "    for p in df[\"node_labels\"]:\n",
    "        if p in [\"\", 'Data Spatiality<br>']:\n",
    "            colors.append(\"white\")\n",
    "        elif p in ['With_SNE']:\n",
    "            colors.append(\"green\")\n",
    "        elif p in [\"WithOut_SNE\"]:\n",
    "            colors.append(\"blue\")\n",
    "    return colors\n",
    "\n",
    "###\n",
    "def tne_color(df):\n",
    "    \"\"\"\n",
    "    fnx to differentiate pie diagram colors, for temporal named entities\n",
    "    \"\"\"\n",
    "    colors = []\n",
    "    for p in df[\"node_labels\"]:\n",
    "        if p in [\"\", 'Data Temporality<br>']:\n",
    "            colors.append(\"white\")\n",
    "        elif p in [\"<1 an\"]:\n",
    "            colors.append(\"blue\")\n",
    "        elif p in [\"1 à 5 ans\"]:\n",
    "            colors.append(\"brown\")\n",
    "        else:\n",
    "            colors.append(\"red\")\n",
    "    return colors\n",
    "\n",
    "###\n",
    "def drw_pie(df, colors):\n",
    "#     colors = tne_color(df)\n",
    "    \"\"\"\n",
    "    fxn to draw pie diagram\n",
    "    \"\"\"\n",
    "    fig=go.Figure(\n",
    "    data=go.Sunburst(\n",
    "        ids=df[\"node_names\"],\n",
    "        labels=df[\"node_labels\"], \n",
    "        parents=df[\"node_parent\"],\n",
    "        marker=dict(colors=colors),\n",
    "        values=df[\"node_counts\"],\n",
    "        branchvalues=\"total\",\n",
    "        texttemplate = ('%{label}',\n",
    "                        '%{label}<br>%{percentParent:.1%}',\n",
    "                        '%{label}<br>%{percentParent:.1%}',\n",
    "                        '%{label}<br>%{percentParent:.1%}',\n",
    "                        '%{label}<br>%{percentParent:.1%}',\n",
    "                        '%{label}<br>%{percentParent:.1%}',\n",
    "                        '%{label}<br>%{percentParent:.1%}',\n",
    "                        '%{label}<br>%{percentParent:.1%}',\n",
    "                        '%{label}<br>%{percentParent:.1%}'),),)\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# corpus_data = pd.read_csv('corpus.csv')\n",
    "def run(corpus_data):\n",
    "    \"\"\"\n",
    "    fxn that separate the corpus, according to the spatio-temporal coverage.\n",
    "    \n",
    "    \"\"\"\n",
    "    corpus_data_tne, range_1, range_2, range_3 = process_date(corpus_data)\n",
    "    \n",
    "    SNE_NODE = {'node_names': ['Corpus', 'With_SNE', 'WithOut_SNE'],\n",
    "                   'node_parent': [\"\", \"Corpus\", \"Corpus\"],\n",
    "                   'node_labels': ['Data Spatiality<br>','With_SNE', 'WithOut_SNE'],\n",
    "                   #'node_counts': [len(corpus),  len(corpus_with_extend), len(corpus_without_extend)]\n",
    "                   'node_counts': [len(corpus_data), corpus_data['ent0'].isna().sum(), len(corpus_data)- corpus_data['ent0'].isna().sum()]\n",
    "                  }\n",
    "    TNE_NODE = {'node_names': ['Corpus',\"WithOut_TNE\",'With_TNE', \"<1 an\", \"1 à 5 ans\",\"> 5 ans\"],\n",
    "                   'node_parent': [\"\", \"Corpus\", \"Corpus\", \"With_TNE\",'With_TNE','With_TNE'],\n",
    "                   'node_labels': ['Data Temporality<br>',\"WithOut_TNE\",'With_TNE',\"<1 an\", \"1 à 5 ans\",\"> 5 ans\"],\n",
    "                   #'node_counts': [len(corpus),  len(corpus_with_extend), len(corpus_without_extend)]\n",
    "                   'node_counts': [len(corpus_data),len(corpus_data)-len(corpus_data_tne),len(corpus_data_tne), len(range_1), len(range_2),len(range_3)]\n",
    "                  }\n",
    "\n",
    "    \n",
    "    df1 = pd.DataFrame(TNE_NODE)\n",
    "    df2 = pd.DataFrame(SNE_NODE)\n",
    "    # colors = sne_color(df)\n",
    "    colors1 = tne_color(df1)\n",
    "    colors2 = sne_color(df2)\n",
    "    return  df1, colors1, df2, colors2\n",
    "#     drw_pie(df,colors)\n",
    "\n",
    "def file_selector(folder_path='.'):\n",
    "    \"\"\"\n",
    "    Fxn to select the database file localy\n",
    "    \"\"\"\n",
    "    filenames = os.listdir(folder_path)\n",
    "    selected_filename = st.selectbox('Select a file', filenames)\n",
    "    return os.path.join(folder_path, selected_filename)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    main Fxn, we build the UI with Streamlit (st) \n",
    "    \"\"\"    \n",
    "#     df_main = pd.DataFrame()\n",
    "    cols = ['name', 'title', 'text', 'pertinence', 'ent0',\t'date', 'thematic']\n",
    "    st.title('3M Thematic Corpus Builder')\n",
    "#     menu = [\"Home\", \"Demo Data\", \"Data\"] # menu to be selected\n",
    "    menu = [\"Demo Data\"] \n",
    "    choice = st.sidebar.selectbox(\"Menu\", menu)\n",
    "    \n",
    "    if choice == \"Demo Data\": # we are using Demo Data menu in this section\n",
    "        st.subheader(\"Parametres de la Recherche\")\n",
    "        txt,start_date, end_date = st.beta_columns([2,1,1])\n",
    "\n",
    "        them_option = txt.selectbox('Choisir une thématique', ('agriculture','hydrologie','urbanisation'))\n",
    "    #         start_date.success(\"start_date\")\n",
    "#         st.write('Thématique :',them_option)# themat)\n",
    "        start_date = start_date.number_input(\"start_date\",1995,2040)\n",
    "#         st.write('Date Initale  :', start_date)\n",
    "#         end_date.success(\"end_date\")\n",
    "        end_date = end_date.number_input(\"end_date\",1996,2040)\n",
    "        st.write('Thématique :',them_option, '\\t     Date Initale  :', start_date, '\\t    Date Finale :', end_date)\n",
    "\n",
    "        \n",
    "        st.subheader(\"Base de données\")\n",
    "#         thematique = st.text_area(\"Nom de thematique --> agriculture or hydrologie or urbanisation\")\n",
    "        filename = file_selector()\n",
    "        st.write('You selected `%s`' % filename)\n",
    "#         filename = st.file_uploader(\"Select an existing DataBase\",type=['jsonl'])\n",
    "        Scrap_button = st.button(\"Start Retriving\") # st.form_submit_button(label = 'submit')\n",
    "        df_main = ''\n",
    "        if Scrap_button:\n",
    "#             file_details = {\"Filename\":filename.name,\"FileType\":filename.type,\"FileSize\":filename.size}\n",
    "#             st.write(file_details)\n",
    "#             col1,col2 = st.beta_columns(2)\n",
    "            df = look_for_thematic_data(filename,them_option)#themat)#thematique)\n",
    "            df = pd.DataFrame(df, columns=cols)\n",
    "            df_main = df\n",
    "\n",
    "            if them_option is not None:\n",
    "                st.write('Paramètres de la recherche :', them_option ,start_date,end_date)\n",
    "#                 df['ent0'] = \n",
    "                st.success('TOP@10 of the Corpus DataFrame')\n",
    "                st.dataframe(df.head(10))\n",
    "                st.write(repr(len(df)) + '  documents dans le corpus')\n",
    "#                 st.write('Size of query corpus : ',df.memory_usage(index=True).sum() )\n",
    "#                 st.write('Size of query corpus : ', df.info(memory_usage='deep'))\n",
    "                st.write('Size of query corpus : ', repr(round(sys.getsizeof(df)/1000000,2))+ ' '+'Mb')\n",
    "#                 st.int(len(df)) : >>> sys.getsizeof(df)\n",
    "\n",
    "#                 st.dataframe(df)\n",
    "#                 st.markdown(get_table_download_link(df), unsafe_allow_html=True)\n",
    "                st.markdown(get_table_download_link_csv(df), unsafe_allow_html=True)\n",
    "                \n",
    "#             Distribution = st.button(\"Vizualise Data Distribution\") # st.form_submit_button(label = 'submit')\n",
    "                st.markdown(\"<h1 style='text-align: center; color: blue;'>Data Spatio-Temporal Distribution</h1>\", unsafe_allow_html=True)\n",
    "#                 col1= st.beta_container()\n",
    "                \"\"\"\n",
    "                divided in two cols, in the first, we display Spatiality diagram et temporality in the second\n",
    "                \"\"\"\n",
    "                col1,col2 = st.beta_columns(2) \n",
    "\n",
    "#                 col1,col2 = st.beta_ # st.beta_columns(2)\n",
    "#             if Distribution:\n",
    "#                 st.success('Quantitative Distribution')\n",
    "                with col1:\n",
    "                    st.success('Spatiality Coverage')\n",
    "                    df1, colors1, df2, colors2 = run(df_main)\n",
    "\n",
    "                                    ###########\n",
    "                    fig2=go.Figure( data=go.Sunburst( ids=df2[\"node_names\"],labels=df2[\"node_labels\"], \n",
    "                        parents=df2[\"node_parent\"],\n",
    "                        marker=dict(colors=colors2),\n",
    "                        values=df2[\"node_counts\"],\n",
    "                        branchvalues=\"total\",\n",
    "                        texttemplate = ('%{label}',\n",
    "                                        '%{label}<br>%{percentParent:.1%}',\n",
    "                                        '%{label}<br>%{percentParent:.1%}'),),)\n",
    "#                     fig2.update_layout(margin = dict(t=0, l=0, r=0, b=0))\n",
    "                    fig2.update_layout(width=250,\n",
    "                                      height=250,\n",
    "                                      autosize=True,\n",
    "                                      margin=dict(t=0, b=0, l=0, r=0),\n",
    "                                      template=\"plotly_white\",)\n",
    "#                     fig2.update_layout(autosize=False, width=500,height=500,)\n",
    "    #                 st.plotly_chart(fig2, use_container_width = True)\n",
    "                    st.plotly_chart(fig2, use_container_width = True)\n",
    "                    ########################\n",
    "                with col2:\n",
    "                    st.success(\"Temporality Coverage\")\n",
    "\n",
    "                    fig1=go.Figure( data=go.Sunburst( ids=df1[\"node_names\"],labels=df1[\"node_labels\"], \n",
    "                        parents=df1[\"node_parent\"],\n",
    "                        marker=dict(colors=colors1),\n",
    "                        values=df1[\"node_counts\"],\n",
    "                        branchvalues=\"total\",\n",
    "                        texttemplate = ('%{label}',\n",
    "                                        '%{label}<br>%{percentParent:.1%}',\n",
    "                                        '%{label}<br>%{percentParent:.1%}',\n",
    "                                        '%{label}<br>%{percentParent:.1%}',\n",
    "                                        '%{label}<br>%{percentParent:.1%}',\n",
    "                                        '%{label}<br>%{percentParent:.1%}'),),)\n",
    "#                     fig1.update_layout(margin = dict(t=0, l=0, r=0, b=0))\n",
    "                    fig1.update_layout(width=250,\n",
    "                                      height=250,\n",
    "                                      autosize=True,\n",
    "                                      margin=dict(t=0, b=0, l=0, r=0),\n",
    "                                      template=\"plotly_white\",)\n",
    "                    st.plotly_chart(fig1, use_container_width = True)\n",
    "                \"\"\"\n",
    "                make two cols for wordcloud viz, spatial and temporal\n",
    "                \"\"\"\n",
    "                col11,col22 = st.beta_columns(2)\n",
    "\n",
    "                with col11:\n",
    "                    st.success('Spatiality WordCloud')\n",
    "                    #Final word cloud after all the cleaning and pre-processing\n",
    "                    wordcloud = WordCloud(background_color='black').generate(' '.join(df['ent0'][df['ent0'].notnull()].astype(str) ))\n",
    "                    plt.imshow(wordcloud)\n",
    "                    plt.axis(\"off\")\n",
    "    #                 plt.show()\n",
    "                    st.pyplot(plt)\n",
    "            \n",
    "                with col22:\n",
    "                    st.success('Temporality WordCloud')\n",
    "                    counts = df['date'].dt.year.value_counts()\n",
    "                    counts.index = counts.index.map(str)\n",
    "                    wordcloud = WordCloud().generate_from_frequencies(counts)\n",
    "                    plt.figure()\n",
    "                    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "                    plt.axis(\"off\")\n",
    "    #                 plt.show()\n",
    "                    st.pyplot(plt)\n",
    "                    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements. txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
